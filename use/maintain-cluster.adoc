---
sidebar: sidebar 
permalink: use/maintain-cluster.html 
keywords: astra, astra data store, kubectl 
summary: 您可以在 Astra Data Store 中使用 kubectl 命令来维护集群。 
---
= 管理Astra数据存储集群
:hardbreaks:
:allow-uri-read: 
:icons: font
:imagesdir: ../media/use/


您可以在Astra Data Store中使用kubectl命令来管理集群。

* <<Add a node>>
* <<Remove a node>>
* <<Place a node in maintenance mode>>
* <<Add drives to a node>>
* <<Replace a drive>>


.您需要什么？ #8217 ；将需要什么
* 安装了 kubectl 和 kubectl-astrad 插件的系统。请参见 link:../get-started/install-ads.html["安装 Astra 数据存储"]。




== 添加节点

要添加的节点应属于 Kubernetes 集群，并且其配置应与集群中的其他节点类似。


NOTE: 要使用Astra控制中心添加节点、请参见 https://docs.netapp.com/us-en/astra-control-center/use/manage-backend.html["将节点添加到存储后端集群"^]。

.步骤
. 如果新节点的dataIP尚未加入Astra Data Store集群CR、请执行以下操作：
+
.. 编辑集群CR并在`adsDataNetworks`*地址*字段中添加额外的dataIP。将以大写字母表示的信息替换为适合您环境的值：
+
[source, kubectl]
----
kubectl edit astradscluster CLUSTER_NAME -n astrads-system
----
.. 保存 CR 。
.. 将节点添加到Astra Data Store集群。将以大写字母表示的信息替换为适合您环境的值：
+
[source, kubectl]
----
kubectl astrads nodes add --cluster CLUSTER_NAME
----


. 否则、只需添加节点即可。将以大写字母表示的信息替换为适合您环境的值：
+
[source, kubectl]
----
kubectl astrads nodes add --cluster CLUSTER_NAME
----
. 验证是否已添加此节点：
+
[source, kubectl]
----
kubectl astrads nodes list
----




== 删除节点

对Astra数据存储使用kubectl命令删除集群中的节点。

.步骤
. 列出所有节点：
+
[source, kubectl]
----
kubectl astrads nodes list
----
+
响应：

+
[listing]
----
NODE NAME           NODE STATUS    CLUSTER NAME
sti-rx2540-534d...  Added       cluster-multinodes-21209
sti-rx2540-535d...  Added       cluster-multinodes-21209
...
----
. 标记要删除的节点。将以大写字母表示的信息替换为适合您环境的值：
+
[source, kubectl]
----
kubectl astrads nodes remove NODE_NAME
----
+
响应：

+
[listing]
----
Removal label set on node sti-rx2540-534d.lab.org
Successfully updated ADS cluster cluster-multinodes-21209 desired node count from 4 to 3
----
+
将节点标记为要删除后、节点状态应从`active`更改为`present`。

. 验证已删除节点的`Present`状态：
+
[source, kubectl]
----
kubectl get nodes --show-labels
----
+
响应：

+
[listing]
----
NAME                                            STATUS   ROLES                  AGE     VERSION   LABELS
sti-astramaster-050.lab.org   Ready    control-plane,master   3h39m   v1.20.0   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=sti-astramaster-050.lab.org,kubernetes.io/os=linux,node-role.kubernetes.io/control-plane=,node-role.kubernetes.io/master=
sti-rx2540-556a.lab.org       Ready    worker                 3h38m   v1.20.0   astrads.netapp.io/cluster=astrads-cluster-890c32c,astrads.netapp.io/storage-cluster-status=active,beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=sti-rx2540-556a.lab.org,kubernetes.io/os=linux,node-role.kubernetes.io/worker=true
sti-rx2540-556b.lab.org       Ready    worker                 3h38m   v1.20.0   astrads.netapp.io/cluster=astrads-cluster-890c32c,astrads.netapp.io/storage-cluster-status=active,beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=sti-rx2540-556b.lab.org,kubernetes.io/os=linux,node-role.kubernetes.io/worker=true
sti-rx2540-534d.lab.org       Ready    worker                 3h38m   v1.20.0   astrads.netapp.io/storage-cluster-status=present,astrads.netapp.io/storage-node-removal=,beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=sti-rx2540-557a.lab.org,kubernetes.io/os=linux,node-role.kubernetes.io/worker=true
sti-rx2540-557b.lab.org       Ready    worker                 3h38m   v1.20.0   astrads.netapp.io/cluster=astrads-cluster-890c32c,astrads.netapp.io/storage-cluster-status=active,beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=sti-rx2540-557b.lab.org,kubernetes.io/os=linux,node-role.kubernetes.io/worker=true
----
. 从节点中卸载Astra数据存储。将以大写字母表示的信息替换为适合您环境的值：
+
[source, kubectl]
----
kubectl astrads nodes uninstall NODE_NAME
----
. 验证是否已从集群中删除此节点：
+
[source, kubectl]
----
kubectl astrads nodes list
----


此节点将从Astra数据存储中删除。



== 将节点置于维护模式

需要执行主机维护或软件包升级时，应将节点置于维护模式。


NOTE: 此节点必须已属于Astra Data Store集群。

当节点处于维护模式时，您无法向集群添加节点。在此示例中、我们会将节点`nhcitj1525`置于维护模式。

.步骤
. 显示节点详细信息：
+
[source, kubectl]
----
kubectl get nodes
----
+
响应：

+
[listing]
----
 NAME             STATUS   ROLES                  AGE     VERSION
 nhcitjj1525      Ready    <none>                 3d18h   v1.23.5
 nhcitjj1526      Ready    <none>                 3d18h   v1.23.5
 nhcitjj1527      Ready    <none>                 3d18h   v1.23.5
 nhcitjj1528      Ready    <none>                 3d18h   v1.23.5
 scs000039783-1   Ready    control-plane,master   3d18h   v1.23.5
----
. 确保节点尚未处于维护模式：
+
[source, kubectl]
----
kubectl astrads maintenance list
----
+
响应（没有节点处于维护模式）：

+
[listing]
----
NAME    NODE NAME  IN MAINTENANCE  MAINTENANCE STATE       MAINTENANCE VARIANT
----
. 启用维护模式。将以大写字母表示的信息替换为适合您环境的值：
+
[source, kubectl]
----
kubectl astrads maintenance create CR_NAME --node-name=NODE_NAME --variant=Node
----
+
例如：

+
[source, kubectl]
----
kubectl astrads maintenance create maint1 --node-name="nhcitjj1525" --variant=Node
----
+
响应：

+
[listing]
----
Maintenance mode astrads-system/maint1 created
----
. 列出节点：
+
[source, kubectl]
----
kubectl astrads nodes list
----
+
响应：

+
[listing]
----
NODE NAME       NODE STATUS     CLUSTER NAME
nhcitjj1525     Added           ftap-astra-012
...
----
. 检查维护模式的状态：
+
[source, kubectl]
----
kubectl astrads maintenance list
----
+
响应：

+
[listing]
----
NAME    NODE NAME       IN MAINTENANCE  MAINTENANCE STATE       MAINTENANCE VARIANT
node4   nhcitjj1525     true            ReadyForMaintenance     Node
----
+
维护` 模式下的 `将以 `false` 开头，并更改为 `true` 。`M状态` 从 `PreparingForMaintenance` 更改为 `ReadyforMaintenance` 。

. 完成节点维护后，禁用维护模式：
+
[source, kubectl]
----
kubectl astrads maintenance update maint1 --node-name="nhcitjj1525" --variant=None
----
. 确保节点不再处于维护模式：
+
[source, kubectl]
----
kubectl astrads maintenance list
----




== 向节点添加驱动器

将kubectl命令与Astra Data Store结合使用、以便向Astra Data Store集群中的节点添加物理或虚拟驱动器。

.您需要什么？ #8217 ；将需要什么
* 一个或多个满足以下条件的驱动器：
+
** 已安装在节点(物理驱动器)中或已添加到节点VM (虚拟驱动器)中
** 驱动器上无分区
** 驱动器当前未被集群使用
** 驱动器原始容量不会超过集群中已获得许可的原始容量(例如、如果许可证为每个CPU核心授予2 TB存储空间、则一个包含10个节点的集群的最大原始驱动器容量为20 TB)
** 驱动器大小至少与节点中其他活动驱动器的大小相同





NOTE: Astra数据存储每个节点所需的驱动器不超过16个。如果您尝试添加第17个驱动器、则驱动器添加请求将被拒绝。

.步骤
. 描述集群：
+
[source, kubectl]
----
kubectl astrads clusters list
----
+
响应：

+
[listing]
----
CLUSTER NAME                    CLUSTER STATUS  NODE COUNT
cluster-multinodes-21209        created         4
----
. 记下集群名称。
. 显示可添加到集群中所有节点的驱动器。将cluster_name替换为集群名称：
+
[source, kubectl]
----
kubectl astrads adddrive show-available --cluster=CLUSTER_NAME
----
+
响应：

+
[listing]
----
Current cluster drive add status
Licensed cluster capacity: 72.0 TiB
Cluster capacity used: 2.3 TiB
Maximum node size without stranding: 800.0 GiB

Node: node1.name
Current node size: 600.0 GiB
Maximum licensed node size: 18.0 TiB
Total size that can be added to this node without stranding: 200.0 GiB
Add drive minimum/reccomended size: 100.0 GiB. Larger disks will be constrained to this size
NAME IDPATH SERIAL PARTITIONCOUNT SIZE ALREADYINCLUSTER
sdg /dev/disk/by-id/scsi-3c290e16d52479a9af5eac c290e16d52479a9af5eac 0 100 GiB false
sdh /dev/disk/by-id/scsi-3c2935798df68355dee0be c2935798df68355dee0be 0 100 GiB false

Node: node2.name
Current node size: 600.0 GiB
Maximum licensed node size: 18.0 TiB
Total size that can be added to this node without stranding: 200.0 GiB
Add drive minimum/reccomended size: 100.0 GiB. Larger disks will be constrained to this size
No suitable drives to add exist.

Node: node3.name
Current node size: 600.0 GiB
Maximum licensed node size: 18.0 TiB
Total size that can be added to this node without stranding: 200.0 GiB
Add drive minimum/reccomended size: 100.0 GiB. Larger disks will be constrained to this size
NAME IDPATH SERIAL PARTITIONCOUNT SIZE ALREADYINCLUSTER
sdg /dev/disk/by-id/scsi-3c29ee82992ed7a36fc942 c29ee82992ed7a36fc942 0 100 GiB false
sdh /dev/disk/by-id/scsi-3c29312aa362469fb3da9c c29312aa362469fb3da9c 0 100 GiB false

Node: node4.name
Current node size: 600.0 GiB
Maximum licensed node size: 18.0 TiB
Total size that can be added to this node without stranding: 200.0 GiB
Add drive minimum/reccomended size: 100.0 GiB. Larger disks will be constrained to this size
No suitable drives to add exist.
----
. 执行以下操作之一：
+
** 如果所有可用驱动器都具有相同的名称、则可以同时将其添加到相应的节点。将以大写字母表示的信息替换为适合您环境的值：
+
[source, kubectl]
----
kubectl astrads adddrive create --cluster=CLUSTER_NAME --name REQUEST_NAME --drivesbyname all=DRIVE_NAME
----
** 如果驱动器的名称不同、您可以一次将其添加到相应的节点中一个(您需要对需要添加的每个驱动器重复此步骤)。将以大写字母表示的信息替换为适合您环境的值：
+
[source, kubectl]
----
kubectl astrads adddrive create --cluster=CLUSTER_NAME --name REQUEST_NAME --drivesbyname NODE_NAME=DRIVE_NAME
----




Astra数据存储创建一个请求以添加一个或多个驱动器、此时将显示一条消息、其中包含此请求的结果。



== 更换驱动器

当集群中的驱动器发生故障时，必须尽快更换驱动器以确保数据完整性。如果某个驱动器发生故障、您可以查看有关集群CR节点状态中的故障驱动器的信息、集群运行状况信息以及指标端点。您可以使用以下示例命令查看故障驱动器信息。

.在 nodeStatuss.driveStatuses 中显示故障驱动器的集群示例
[source, kubectl]
----
kubectl get adscl -A -o yaml
----
响应：

[listing]
----
...
apiVersion: astrads.netapp.io/v1alpha1
kind: AstraDSCluster
...
nodeStatuses:
  - driveStatuses:
    - driveID: 31205e51-f592-59e3-b6ec-185fd25888fa
      driveName: scsi-36000c290ace209465271ed6b8589b494
      drivesStatus: Failed
    - driveID: 3b515b09-3e95-5d25-a583-bee531ff3f31
      driveName: scsi-36000c290ef2632627cb167a03b431a5f
      drivesStatus: Active
    - driveID: 0807fa06-35ce-5a46-9c25-f1669def8c8e
      driveName: scsi-36000c292c8fc037c9f7e97a49e3e2708
      drivesStatus: Active
...
----
故障驱动器CR会在集群中自动创建、其名称与故障驱动器的UUID对应。

[source, kubectl]
----
kubectl get adsfd -A -o yaml
----
响应：

[listing]
----
...
apiVersion: astrads.netapp.io/v1alpha1
kind: AstraDSFailedDrive
metadata:
    name: c290a-5000-4652c-9b494
    namespace: astrads-system
spec:
  executeReplace: false
  replaceWith: ""
 status:
   cluster: arda-6e4b4af
   failedDriveInfo:
     failureReason: AdminFailed
     inUse: false
     name: scsi-36000c290ace209465271ed6b8589b494
     path: /dev/disk/by-id/scsi-36000c290ace209465271ed6b8589b494
     present: true
     serial: 6000c290ace209465271ed6b8589b494
     node: sti-rx2540-300b.lab.org
   state: ReadyToReplace
----
[source, kubectl]
----
kubectl astrads faileddrive list --cluster arda-6e4b4af
----
响应：

[listing]
----
NAME       NODE                             CLUSTER        STATE                AGE
6000c290   sti-rx2540-300b.lab.netapp.com   ard-6e4b4af    ReadyToReplace       13m
----
.步骤
. 使用`kubectl astrad faileddrive show-replacements`命令列出可能的替代驱动器、该命令可筛选符合更换限制(集群中未使用、未挂载、无分区且等于或大于故障驱动器)的驱动器。
+
要在不筛选可能的替代驱动器的情况下列出所有驱动器，请在 `sHow-replacements` 命令中添加 ` -all` 。

+
[source, kubectl]
----
kubectl astrads faileddrive show-replacements --cluster ard-6e4b4af --name 6000c290
----
+
响应：

+
[listing]
----
NAME  IDPATH             SERIAL  PARTITIONCOUNT   MOUNTED   SIZE
sdh   /scsi-36000c29417  45000c  0                false     100GB
----
. 使用 `replace` 命令将驱动器替换为已传递的序列号。如果 ` -wait` 时间已过，则命令将完成替换或失败。
+
[source, kubectl]
----
kubectl astrads faileddrive replace --cluster arda-6e4b4af --name 6000c290 --replaceWith 45000c --wait
----
+
响应：

+
[listing]
----
Drive replacement completed successfully
----
+

NOTE: 如果使用不适当的 ` -replaceWith` 序列号执行 `kubectl astrad faileddrive replace` ，则会显示类似以下内容的错误：

+
[source, kubectl]
----
kubectl astrads replacedrive replace --cluster astrads-cluster-f51b10a --name 6000c2927 --replaceWith BAD_SERIAL_NUMBER
Drive 6000c2927 replacement started
Failed drive 6000c2927 has been set to use BAD_SERIAL_NUMBER as a replacement
...
Drive replacement didn't complete within 25 seconds
Current status: {FailedDriveInfo:{InUse:false Present:true Name:scsi-36000c2 FiretapUUID:444a5468 Serial:6000c Path:/scsi-36000c FailureReason:AdminFailed Node:sti-b200-0214a.lab.netapp.com} Cluster:astrads-cluster-f51b10a State:ReadyToReplace Conditions:[{Message: "Replacement drive serial specified doesn't exist", Reason: "DriveSelectionFailed", Status: False, Type:' Done"]}
----
. 要重新运行驱动器更换，请使用 ` -force` 和上一个命令：
+
[source, kubectl]
----
kubectl astrads faileddrive replace --cluster astrads-cluster-f51b10a --name 6000c2927 --replaceWith VALID_SERIAL_NUMBER --force
----




== 有关详细信息 ...

* link:../use/kubectl-commands-ads.html["使用kubectl命令管理Astra Data Store资源"]
* https://docs.netapp.com/us-en/astra-control-center/use/manage-backend.html#add-nodes-to-a-storage-backend-cluster["将节点添加到Astra控制中心的存储后端集群"^]

